### K近邻

- 当训练集、距离度量、K值以及分类决策规则确定后，对于任何一个新的输入实例，它所属的类唯一地确定。

**距离度量**

- 欧式距离
- 曼哈顿距离（L1）
- 切比雪夫距离
- 闵可夫斯基距离（包含前三种）
- 标准化欧氏距离
- 夹角余弦

**K值的选择**

- 较小的k值，学习的近似误差（training error）会减小，估计误差（test error）会增大，整体模型变得复杂，容易过拟合（容易受到训练数据的噪声影响）
- 较大的k值，学习的估计误差会减小，近似误差会增大，整体的模型变得简单
- k=N，无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类，模型过于简单，完全忽略最近邻列表中可能包含远离其近邻的数据点，是不可取的
- K值一般取一个比较小的数值，通常采用交叉验证法（cv）来选取最优的K值（经验规则：K一般低于训练样本数的平方根）

**分类决策规则**

- 多数表决

**优点**

- 简单、易于理解、易于实现
- 无需估计参数、无需训练
- 适合对稀有事件（rare event)进行分类
- 特别适合多分类问题（multiclass），如根据基因特征来判断其功能分类，KNN比SVM的表现要好

**缺点**

- 懒惰算法，分类计算量大，内存开销大（因为要扫描全部训练样本并计算距离），已经有一些方法提高计算的效率，例如压缩训练样本量
- 可解释性较差，无法像决策树那样
- 当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数
- 消极学习法（lazy learner），相对应的是积极学习（eager learner）的决策树

### 线性回归

- 线性回归假设特征和结果满足线性关系
- 每个特征变量可以首先映射到一个函数，然后再参与线性计算，这样就可以表达特征与结果之间的非线性关系
- y=ax+...+?x+b 权重a，截距b
- 在一些应用场合中，需要将输入空间x=(1,x1,x2,...,xn)映射到特征空间（feature space）中，然后建模,特征映射相关技术包括特征哈希、特征学习、Kernel等

**目标函数**

- 损失函数（loss function），平方损失函数（squared loss）
- 极大似然估计（根据中心极限定理，认为变量之和服从高斯分布，MLE把高斯分布的条件概率相乘）与损失函数极小化等价

**参数估计**

- 最小二乘法
- （批量，随机）梯度下降法（Batch/Stochastic/GD）
- 训练样本集较大时，一般使用SGD

**逻辑回归**

- logistic dist，对数几率（oods）,sigmoid
- 实际场景中，我们用其预测值作为事件发生的概率，而非绝对的分类问题
- MLE把伯努利分布（Bernoulli dist）的结果相乘

**参数估计**

- MLE就是最小化交叉熵误差（Cross Entropy Error）
- Batch GD，共轭梯度法（Conjugate Gradient），拟牛顿法（LBFGS），ADMM分布学习算法
- 分类边界：0.5

**其他**

- 线性不可分的数据，可以通过特征变换的方式把低维空间转换到高维空间（kernel trick），线性可分的几率会高一些。
	- 不过，通常使用的kernel都是隐式的，也就是找不到显式地把数据从低维映射到高维的函数，而只能计算高维空间中的数据点的内积。
	- 在这种情况下，LR就不能再表示成原始形式wTx+b （primal form），而只能表示成对偶形式$\sum_ia_i+b$（dual form）,不仅需要存储各个ai，还要存储训练数据xi本身，这个存储量就大了。
- 相比之下，SVM的对偶形式是稀疏的，即只有支持向量的ai才非零，才需要存储相应的xi，所以，在非线性可分的情况下，SVM用的更多
- LR是一种判别模型（discriminative），直接对条件概率P(y|x)建模，而不关心背后的数据分布P(x,y),而高斯贝叶斯（Gaussian Naive Bayes）是一种生成模型（generative），先对数据的联合分布建模，再通过贝叶斯公式来计算属于各个类别的后验概率（posterior）
- Softmax 回归是对LR在多分类的推广，也叫多元逻辑回归（Multinomial LR）
- LR与SVM
	- 损失函数不同，LR用的是logistical loss，SVM是hinge loss
	- 但目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重
	- SVM只考虑support vectors，也就是和分类最相关的少数点，去学习分类器
	- LR通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重，根本目的一样
	- 根据需要，两个方法都可以增加不同的正则化项，如l1,l2等等
	- LR模型易于理解，特别是大规模线性分类时比较方便；SVM的理解和优化相对来说复杂，转化为对偶问题后，分类只需要计算与少数几个support vector的距离，这个在进行复杂核函数计算时优势很明显，能够大大简化模型和计算量。
	- 对异常的敏感度
		- LR中每个样本都是有贡献的，最大似然后会自动压制异常的贡献
		- SVM对异常比较敏感，因为其训练只需要支持向量，有效样本本来就不高，一旦被干扰，预测结果难以预料

### 决策树

- 具有可读性，分类速度快
- （内部-一个特征或属性/叶-一个类）结点，有向边
- 由根结点到叶节点的每一条路径构建*规则*；路径上内部结点的特征对应着规则的*条件*，而叶结点的类对应着规则的*结论*
- 性质：互斥且完备（每一个实例都被一条路径或一条规则所覆盖，且只被一条路径或一条规则所覆盖，这里的覆盖是指实例的特征与路径上的所有特征或规则的条件一致）

**特征选择**

- 准则：Info Gain
- 熵：$H(X)=-\sum_{i=1}^n p_i\log p_i$, 当pi=0时，定义熵为0，单位为比特或者纳特
- 条件熵：$H(Y|X)=\sum_{i=1}^n p_iH(Y|X=x_i)$
- 经验熵和经验条件熵：当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为经验熵和条件经验熵
- 信息增益：表示得知特征X的信息而使得类*Y的不确定性减少的程度*，对数据集D，信息增益$g(D,A)=H(D)-H(D|A)$
- 信息增益比：信息增益$g(D,A)$与训练数据集D关于特征A的值的熵$H_A(D)$之比
- Gini系数：假设有K个类，样本点属于第k类的概率为pk, 则$Gini(p)=\sum_{k=1}^K p_k(1-p_k)$，基尼系数越大，样本集合的不确定性越大，与熵类似

**算法**

- ID3
	- 从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点
	- 再对子结点递归地调用以上方法，构建决策树
	- 直到所有特征的信息增益均很小，或没有特征可以选择为止
	- 用极大似然法进行概率模型的选择
	- 容易过拟合
- C4.5
	- 改进了ID3，用信息增益比来选择特征
- CART
	- 由特征选择、树生成及剪枝组成，既可用于分类也可用于回归
	- 假定决策树是二叉树，用基尼系数（Gini index）最小化准则，进行特征选择
	- 用验证数据集对已生成的树进行剪枝，并选择最优子树，用损失函数最小作为剪枝的标准

**剪枝**

- $C(T)$为对训练数据的预测误差（如基尼系数），$|T|$为子树的叶结点个数，$a\ge0$为参数,$C_a(T)$为参数是a时的子树T的整体损失，参数a权衡训练数据的拟合程度与模型的复杂度
- a 大的时候，最优子树Ta偏小；当a小的时候，最优子树Ta偏大；a=0时，完整的树是最优的；a→∞ 时，根结点组成的单结点树是最优的
- 在剪枝得到的子树序列T0,T1,…,Tn中通过交叉验证选取最优子树Ta

### 随机森林

- bootstrap抽样，特征维度M，选择维度m
- 可生成一个$Proximities=（pij）$矩阵，用于度量样本之间的相似性： $p_{ij}=a_{ij}/N,a_{ij}$表示样本i和j出现在随机森林中同一个叶子结点的次数，N为随机森林中树的颗数
- 对generlization error使用的是无偏估计

**优点**

- 随机性的引入，使得RF不容易过拟合
- 随机性的引入，使得RF有很好的抗噪声能力
- 很好的高维度（feature很多）的数据
- 不用做特征选择
- 对数据集的适应能力强：既能处理离散型数据，也能处理连续型数据，数据集无需规范化
- 训练速度快，可以得到变量重要性排序（两种：基于OOB误分率的增加量，基于分裂时的GINI下降量）
- 在训练过程中，能够检测到feature间的互相影响
- 容易做成并行化方法
- 实现比较简单

**影响分类效果的参数**

- 森林中任意两棵树的相关性：相关性越大，错误率越大
- 森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低
- 减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大，所以关键问题是如何选择最优的m

**袋外误差率(OOB)**

- n个样本的训练集随机采样，采集n次，当n→∞时，$(1-1/n)^n→1/e=36.8%$，也就是Out of Bag的数据，这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力
- oob计算方式
	- 对每个样本计算它作为oob样本的树对它的分类情况
	- 以简单多数投票作为该样本的分类结果
	- 最后用误分个数占样本总数的比率作为随机森林的oob误分率

**算法**

- 两个随机：抽样随机，特征选择随机

- 有放回抽样的原因：如果不是有放回的抽样，那么每棵树的训练样本都是不同的，没有交集，这样每棵树都是片面的，训练出来有很大的差异，随机森林最后分类取决于多棵树（弱分类器）的投票表决，这种表决应该是”求同”，因此使用完全不同的训练集来训练每棵树这样对最终分类结果没有帮助

- RF相比bagging的改进
	- RF选与输入样本的数目*相同*多的次数（可能一个样本会被选取多次，同时也会造成一些样本不会被选取到），而bagging一般选取比输入样本的数目少的样本
	- bagging是用全部特征来得到分类器，而RF是需要从全部特征中选取其中的*一部分*特征来训练得到分类器； 效果更好

- 不剪枝的原因：之前的两个随机采样的过程保证了随机性，所以就算不剪枝，也不会出现over-fitting。，按这种算法得到的随机森林中的每一棵都很弱，但是组合起来很厉害

- 变体：不用决策树，反而把SVM，LR的分类器当作一棵树的方法也叫RF。比如回归问题，做100次bootstrap，每次得到的数据Di长度为N，对于每一个Di，使用局部回归(LOESS)拟合一条曲线，将这些曲线取平均，得到的最终拟合曲线更加稳定，并且过拟合明显减弱

### AdaBoost

**集成学习**

- ensemble learning是指通过构建多个弱学习器，然后结合为一个强学习器来完成分类任务。集成学习并不算是一种分类器，而是一种学习器结合的方法，通过使用多个决策者共同决策一个实例的分类从而提高分类器的泛化能力
	- 首次按产生一组“个体学习器”，这些个体学习器可以是同质的（homogeneous）（例如全部是决策树），这一类学习器被称为基学习器（base learner），相应的学习算法称为“基学习算法”
	- 集成也可包含不同类型的个体学习器（例如同时包含决策树和神经网络），这一类学习器被称为“组件学习器”（component learner）
- 条件
	- 分类器之间应该具有差异性，多样性
	- 每个个体分类器的分类精度必须大于0.5，如果p<0.5那么随着集成规模的增加，分类精度会下降；反之，最后最终分类精度是可以趋于1的
- 分类
	- 个体学习器之间存在强依赖关系、必须串行生成的序列化方法，代表是Boosting
	- 个体学习器间不存在强依赖关系、可同时生成的并行化方法，代表是Bagging和RF
	- Bagging通过降低基分类器方法来改善泛化能力，因此性能依赖于基分类器的稳定性
		- 如果基分类器是不稳定的，Bagging有助于减低训练数据的随机扰动导致的误差
		- 如果基分类器是稳定的，即对数据变化不敏感，那么Bagging方法就得不到性能的提升，甚至会降低
	- Boosting是一个迭代的过程，通过改变样本分布，使得分类器聚集在那些很难分的样本上，对那些容易错分的数据加强学习，增加错分数据的权重，这样错分的数据再下一轮的迭代就有更大的作用（对错分数据进行惩罚）
	- Bagging与Boosting的区别
		- 取样方式不同
			- Bagging采用均匀取样，Boosting根据错误率来取样，因此Boosting的分类精度要优于Bagging
			- Bagging的训练集的选择是随机的，各轮训练集之间相互独立，而Boostlng的各轮训练集的选择与前面各轮的学习结果有关
			- Bagging的各个预测函数没有权重，而Boosting是有权重的
			- Bagging的各个预测函数可以并行生成，而Boosting的各个预测函数只能顺序生成
			- 对于神经网络这样极为耗时的学习方法，Bagging可通过并行训练节省大量时间开销
		- bagging是减少variance，而boosting是减少bias

**算法**

- 每一轮改变训练数据的权值或概率分布：提高前一轮弱分类器错误分类样本的权值，降低正确分类样本的权值
- 对弱分类器的组合：加权多数表决。加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用；减小分类误差率较大的弱分类器的权值，使其在表决中起较小的作用
- 具体步骤
	- 初始化训练样本的权值分布。如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：1/N
	- 训练弱分类器。每一轮改变训练数据的权值或概率分布，权值更新过的样本被用于训练下一个分类器，整个训练过程迭代地进行下去
	- 组合弱分类器。误差率低的弱分类器在最终分类器中权重较大，否则较小，迭代得到最终分类器
- 可以证明Adaboost的训练误差是以指数速率下降的
- 算法的数学推导
	- 加法模型additive model
	- 损失函数极小化
	- 前向分布算法forward stagewise algorithm

### GBDT

- Gradient Boosting Decision Tree，又叫 MART（Multiple Additive Regression Tree），广泛应用在搜索排序、点击率预估，竞赛中最为常用的一种机器学习算法

**回归树Regression DT**

- 最优切分变量和最优切分点衡量的准则不再是分类树中的基尼系数，而是平方误差最小化
- 分枝直到每个叶子节点上的值唯一或者达到预设的终止条件（比如叶子个数上限），那则预测为该节点上的平均值
- GBDT的核心在与叠加每一步每一棵树拟合的残差和选择分裂点的评价方式

**提升树Boosting DT**

- 提升方法采用加法模型（即基函数的线性组合）与前向分布算法，提升树是迭代多棵回归树来共同决策

- 当采用平方误差损失函数时，每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树，提升树即是整个迭代过程生成的回归树的累加。模型表示为$f_M(x)=\sum_{m=1}^M T(x;p_m)$，其中T为决策树，$p_m$为决策树的参数，M为树的个数

- Boosting DT算法
	- 初始化模型$f_0(x)=0$
	- 对$m=1,2,...,M$
		- 计算残差$r_{mi}=y_i-f_{m-1}(x_i),i=1,2,...,N$
		- 拟合残差$r_{mi}$学习一个回归树，得到$T(x;p_m)$
		- 更新$f_m(x)=f_{m-1}(x)+T(x;p_m)$

**算法**

- 假设前一轮得到的强学习器为$f_{t−1}(x)$，对应的损失函数则为$L(y,f_{t−1}(x))$,新一轮迭代的目的就是找到一个弱分类器$h_t(x)$，使得损失函数$L(y,f_{t−1}(x)+h_t(x))$达到最小

- 初始化弱分类器，估计使损失函数极小化的一个常数值，此时树仅有一个根结点：$f_0(x)=argmin(c)\sum_{i=1}^N L(y_i,c)$

- 对$m=1,2,...,M$
	- 对i=1,2,...,N，计算损失函数的负梯度值在当前模型的值，将它作为残差的估计：$r_{mi}=-\frac{L'(y,f_{m-1}(x_i))}{f_{m-1}'(x_i)}$，对于平方损失函数，它就是通常所说的残差；对于一般损失函数，它就是残差的近似值
	- 对$r_{mi}$拟合一个回归树，得到第m棵树的叶结点区域$R_{mj}，j=1,2,⋅⋅⋅,J$
	- 对$j=1,2,...,J$，计算$c_{mj}=argmin\sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i)+c)$，即利用线性搜索估计叶结点区域的值，使损失函数极小化
	- 更新回归树：$f_m(x)=f_{m-1}(x)+\sum_{j=1}^J c_{mj}I(x\in R_{mj})$

**问题**

- 为什么xgboost/gbdt在调参时为什么树的深度很少就能达到很高的精度？
	- 参考bagging和boosting的核心不同点

### XGBoost

**监督学习的要素**

- 模型，参数，目标函数：误差函数+正则化项
- 误差函数：如平方损失，logistic损失: $y_iln(1+e^{-y_i})+(1-y_i)ln(1+e^{y_i})$
- 正则化项：如L1正则(lasso稀疏)，L2正则(Ridge平滑)，通过约束噪声和outlier数据的权重，降低了模型复杂度，从而预防了过拟合，提高了泛化性

**推导**

- xgboost的误差函数：平方误差->二阶泰勒展开
- 目标函数的最小化：解一个关于W的一元二次方程最小值问题，得到最小（最好）的结构分数（structure score，类比Gini）
- xgboost利用贪心法计算信息增益，比枚举每个树的结构分数效率高
- 为了限制树的生长加入阈值γ，当增益大于阈值时才让节点分裂，它是正则项里叶子节点数T的系数，所以xgboost在优化目标函数的同时相当于做了预剪枝
- 系数λ是正则项里leaf score的L2模平方的系数，对leaf score做了平滑，也起到了防止过拟合的作用，GBDT里不具备

**问题**

- GBDT和XGBOOST的区别？
	- 基分类器的选择：GBDT只能以CART作为基分类器，XGBoost可以是CART或者线性分类器，后者相当于带L1和L2正则化项的LogitR（分类问题）或者LinearR（回归问题）
	- 二阶泰勒展开：GBDT在优化时只用到一阶导数，XGBoost用到了二阶。XGBoost工具支持自定义损失函数，只要函数可一阶和二阶求导
	- 方差-方差权衡（Bias-variance tradeoff)：XGBoost在正则项里包含了树的叶子节点个数T、每个叶子节点上输出分数的L2模的平方和。正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合
	- 列抽样（column subsampling）：XGBoost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算
	- 缺失值处理：XGBoost考虑了训练数据为稀疏值的情况，可以为缺失值或者指定的值指定分支的默认方向
	- XGBoost支持并行：XGBoost也是一次迭代完才能进行下一次迭代，但其并行是在特征上的
		- 决策树的学习最耗时的是对特征的值进行排序（因为要确定最佳分割点）
		- XGBoost在训练之前，预先对数据进行了排序，然后保存为block(块)结构，后面的迭代中重复地使用这个结构，大大减小计算量
		- block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以多线程进行
	- 线程缓冲区存储：按照特征列方式存储能优化寻找最佳的分割点，但是当并行计算梯度数据时会导致内存的不连续访问，严重时会导致cache miss，降低算法效率
		- 可先将数据收集到线程内部的buffer（缓冲区），主要是结合多线程、数据压缩、分片的方法，然后再计算，提高算法的效率
	- 可并行的近似直方图算法：树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点
		- 当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点
		- 根据百分位法列举几个可能成为分割点的候选者，然后从候选者中根据上面求分割点的公式计算找出最佳的分割点
- 为什么在实际的 kaggle 比赛中 gbdt 和 random forest 效果非常好？
	- ensemble，更不容易overfit
	- 基于树的算法抗噪强，比如容易对缺失值进行处理
	- feature一般有很多，更适合tree based

**其他**

- Shrinkage（缩减）：学习速率（xgboost中的ϵ）。XGBoost每次迭代后会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。一般把ϵ设置得小一点，然后迭代次数设置得大一点。（传统GBDT也有学习速率）

### 感知机

- 线性方程$wx+b=0$对应特征空间$R^n$中的一个超平面S，其中w是超平面的法向量，b是超平面的截距，超平面将特征空间划分为两个部分

**算法**

- Perceptron采用不同的初值或选取不同的误分类点，解可以不同
- 原始形式
	- 只有当一个实例点被*误分类*时，调整w,b的值，使分离超平面向该误分类点的一侧移动，减少该误分类点与超平面的距离，直至超平面越过该误分类点使其被正确分类
- 对偶形式
	- 将w和表示为实例$x_i$和标记$y_i$线性组合的形式
	- $w=\sum_{i=1}^N n_iηy_ix_i, b=\sum_{i=1}^N a_iy_i$
	- 当$η=1$时，表示第i个实例点由于误分而进行更新的次数。实例点更新次数越多，意味着它距离分离超平面越近，也就越难正确分类，这样的实例对学习结果影响最大
	- 对偶形式的训练实例仅以内积的形式出现。为了方便，可预先将训练实例间的内积计算出来并以矩阵的形式存储，这个矩阵就是*Gram矩阵*，$G=[x_ix_j]_{N*N}$
	- 对偶形式迭代是收敛的，存在多个解
- 对偶形式算法
	- *线性可分的*训练数据集$T={(x_1,y_1),(x_2,y_2),⋅⋅⋅,(x_N,y_N)},y_i\in (−1,+1),w=(w_1,w_2,...,w_N)^T,i=1,2,⋅⋅⋅,N,0<η\le 1$
	- 输入$w,b,f(x)=sign((\sum_{j=1}^N w_jy_jx_i)x+b)$
	- $a=0,b=0$
	- choose random $(x_i,y_i)$
	- if $y_i((\sum_{j=1}^N w_jy_jx_j)x_i+b)\le 0$
		- $w_i+=η$
		- $b+=ηy_i$
	- else done
- 原始形式适合online learning，即根据新数据的到来继续更新感知机；对偶形式更适合offline learning，因为储存了一个Gram内积矩阵
- 感知机收敛定理证明：当线性可分时，必定能找到解（待补充）

### 朴素贝叶斯

- Naive Bayes对于给定的训练数据集，首先基于特征条件独立假设学习输入、输出的*联合分布*；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y
- NB的强假设：各个特征互相独立

**推导**

- 有k个特征，$y=(y_1,y_2,...,y_k)$
- 求$argmax(y_k)P(y_k|x)$
- 贝叶斯定理为$P(y_k|x)=\frac{P(x|y_k)P(y_k)}{P(x)}$，分母可以分解为$\sum_{i=1}^n P(x|y_k)P(y_k)$
- 其中先验(prior)概率$P(y_k)$从数据集已知
- 强假设可得$P(x|y_i)=\Pi_{i=1}^n P(x_i|y_i)$，参数规模为$\sum_{i=1}^n S_ik$，$S_i$是第i个特征$x_i$可以取值的个数
- 于是贝叶斯分类器为$f(x)=argmax(y_k)P(y_k|x)=argmax(y_k)\frac{P(y_k)\Pi_{i=1}^n P(x_i|y_k)}{\sum_k P(y_k)\Pi_{i=1}^n P(x_i|y_k)}$
- 分母对argmax没有影响，可以表示为$f(x)=argmax(y_k)P(y_k)\Pi_{i=1}^n P(x_i|y_k)$

**参数估计**

- 先验概率$P(Y=c_k)$极大似然估计是用样本中ck的出现次数除以样本容量
- 如果训练数据中没有出现某种参数与类别的组合，MLE估计会是0，会影响到后验概率的计算结果，使分类产生偏差
	- 贝叶斯估计：多了一个λ，当λ=0时就是极大似然估计，常取λ=1，这时称为*拉普拉斯平滑*Laplace Smoothing
	- 先验概率的Bayes Estimate：
		- $P_λ(Y=c_k)=\frac{\sum_{i=1}^N I(y_i=c_k)+λ}{N+Kλ}$
	- 条件概率的Bayes Estimate：
		- $P_λ(X_j=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^N I(x_{ij}=a_{jl},y_i=c_k)+λ}{\sum_{i=1}^N I(y_i=c_k)+S_jλ}$

### 聚类

- 

### 问题汇总

**判别式和生成式模型的区别**

- 生成式模型估计它们的联合概率分布P(x,y)，关注数据是如何生成的，反映同类数据本身的相似度，不关心到底划分不同类的边界在哪
- 判别式模型估计条件概率分布P(y|x)，关注类别之间的差别
- 生成式模型可以根据贝叶斯公式得到判别式模型，但反过来不行
- 判别式模型主要有：
	- logit R, Linear R
	- SVM, Neural Network
	- KNN
	- Gaussian Process高斯过程
	- CRF条件随机场
	- Boosting
	- CART
	- LDA(linear Discriminant analysis)线性判别分析
- 生成式模型主要有:
	- NB(Naive Bayes), BN(Bayes Network)
	- HMM
	- Mixture Gaussians
	- Sigmoid Belief Network
	- Markov Random Fields
	- DBN深度信念网络
	- Latent Dirichlet Allocation

**时间序列模型**

- AR模型：自回归模型，是一种线性模型，已知N个数据，可由模型推出第N点前面或后面的数据（设推出P点），所以其本质类似于插值
- MA模型：移动平均法模型，使用趋势移动平均法建立直线趋势的预测模型
- ARMA模型：自回归滑动平均模型，模型参量法高分辨率谱分析方法之一，研究平稳随机过程有理谱的典型方法。它比AR模型法与MA模型法有较精确的谱估计及较优良的谱分辨率性能，但参数估算比较繁琐
- GARCH模型：广义ARCH模型，是ARCH模型的拓展， GARCH对误差的 方差进行建模，特别适用于波动性的分析和 预测

**无监督学习**

- 模型
	- 聚类
	- 自编码器auto-encoder
	- 主成分分析PCA
	- GAN
- 算法
	- EM

**GBDT和RF比较**

- 参考bagging和boosting的对比
- 都是由多棵树组成和决定结果
- RF可以是分类树，也可以是回归树；GBDT只由回归树组成
- RF可以并行；GBDT只能串行
- RF采用多数投票；GBDT将所果加权累加
- RF对异常值不敏感，GBDT对异常值非常敏感
- RF对数据一视同仁，GBDT是基于权值的弱分类器的集成
- RF减少variance提高性能，GBDT减少bias提高性能

### 参考资源

- https://plushunter.github.io/tech-stack/
